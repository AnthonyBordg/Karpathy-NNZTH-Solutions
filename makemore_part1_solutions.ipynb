{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building Makemore Part 1 - Exercise Solutions  "
      ],
      "metadata": {
        "id": "_RkNx4RULNou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ex1: train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss. Did it improve over a bigram model?   "
      ],
      "metadata": {
        "id": "u8GsmyWLM9ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download the names.txt file from github\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0MXvXgejJoH",
        "outputId": "49540ab0-6e59-4e17-961a-eac2b2cea030"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-21 21:46:14--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "names.txt           100%[===================>] 222.80K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-09-21 21:46:15 (1.98 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing our list of words\n",
        "words = open('names.txt', 'r').read().splitlines()"
      ],
      "metadata": {
        "id": "GU4WlqkvNt-g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAFXf6RKRg25",
        "outputId": "c34d43ae-3f5e-486c-ca73-69558e554f8b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma',\n",
              " 'olivia',\n",
              " 'ava',\n",
              " 'isabella',\n",
              " 'sophia',\n",
              " 'charlotte',\n",
              " 'mia',\n",
              " 'amelia',\n",
              " 'harper',\n",
              " 'evelyn']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our \"string-to-index\" dictionary\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ],
      "metadata": {
        "id": "2RJzWNrwaEgK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# create the training dataset\n",
        "xs, ys = [], []\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    iy = stoi[ch3]\n",
        "    xs.append([ix1, ix2])\n",
        "    ys.append(iy)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ],
      "metadata": {
        "id": "T1-xMR12XCCH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here be aware that contrary to what happens in Andrej's lecture on bigrams\n",
        "# where `xs` is a 1-dim tensor, `xs.nelement()` won't return the number of\n",
        "# training examples, but the total number of elements in `xs` (in our case two\n",
        "# times the number of training examples). Use `.size(0)` or `.shape[0]` instead.\n",
        "num = xs.size(0)\n",
        "print('number of elements in our training dataset: ', num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "triGEiwCbhJD",
        "outputId": "8f16ac95-22cb-4789-f83f-3714b3e02513"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of elements in our training dataset:  196113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs.shape, ys.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uac6mz-yrXT9",
        "outputId": "5d161bed-6bbf-44fd-cba0-3a28f6953590"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([196113, 2]), torch.Size([196113]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs[:4], ys[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFPW6H1LspJS",
        "outputId": "af63d0e2-691e-4e72-c9a1-ddd1ae17cfbb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  5],\n",
              "         [ 5, 13],\n",
              "         [13, 13],\n",
              "         [13,  1]]),\n",
              " tensor([13, 13,  1,  0]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will train a trigram language model using a neural network with a single layer\n",
        "# of 27 neurons (one neuron per class, i.e for each character) each receiving\n",
        "# now 27 + 27 = 54 inputs, instead of 27 inputs for the bigram model, since now\n",
        "# a bigram starting a trigram will be encoded into a 54-dim vector.\n",
        "# Indeed, a pair of indices (i,j) will be encoded into a 54-dim vector with a 1\n",
        "# at the i-th position and also at the (27+j)-th position and 0 elsewhere.\n",
        "\n",
        "# `xs` is a matrix, i.e. a 2-dim tensor, with 196113 rows and 2 columns.\n",
        "xs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAnDsvRnUs9x",
        "outputId": "f30b8c96-9026-419d-a99b-3b1467784a0e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([196113, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot encoding of `xs` will make it into a 3D tensor of size (196113, 2, 27)\n",
        "import torch.nn.functional as F\n",
        "\n",
        "xenc = F.one_hot(xs, num_classes=27).float()\n",
        "xenc.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHe0gYvWVS71",
        "outputId": "8cfd3c79-bf37-4a63-a7e5-5df588c106e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([196113, 2, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xenc.view(-1, 27*2).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjdIHbH2frkP",
        "outputId": "da56c821-89b5-4d66-a473-c407de81bc84"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([196113, 54])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To input `xs` to our network, we need to flatten it into a (196113, 54)-matrix.\n",
        "# This way, we will have encoded an element of our training dataset, i.e. a pair\n",
        "# of indices encoding a bigram, into a 54-dim vector (versus a 27-dim vector in the\n",
        "# case of the bigram model in Andrej's lecture)."
      ],
      "metadata": {
        "id": "m1_vvQetV6jq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the 'network'\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27+27, 27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "id": "G-idEd3RjU2S"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampling before training (spoiler: It's terrible!)\n",
        "\n",
        "for i in range(20):\n",
        "\n",
        "  out = []\n",
        "  ix1 = 0\n",
        "  ix2 = 0\n",
        "  while True:\n",
        "\n",
        "    xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=27).float()\n",
        "    xenc = xenc.view(-1, 27*2)\n",
        "    logits = xenc @ W # predict log-counts\n",
        "    counts = logits.exp() # counts\n",
        "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "\n",
        "    ix1 = ix2\n",
        "    ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix2])\n",
        "    if ix2 == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2FsRkKgvyF7",
        "outputId": "2607bed3-010b-430c-c7f6-65895c218850"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "owo.\n",
            "ziipijpgcdhiupgbdnnbxutfkhltr.\n",
            "anfspzxsshcdhk.\n",
            "zogvkbdkztaotadhkpgjppgxktwdnu.\n",
            "bxoemziadbjmqadfkcnbjmuthsdziwlvp.\n",
            "cochvxyedvpumyyftbdqaawlfyfwbelapxsshpgaocfvpgllbnvlenadsdziu.\n",
            "zpgcbjpqgqqo.\n",
            ".\n",
            "ozikqllonkdhaqxqztiu.\n",
            "nyvwhuhochkvlmybdujyigemcgjxqaongqlroogdppmcrhmydhvshakoxgjllopgjdzqaydgjpghfiupfydtawdzrpbxtanjpkxtstzxyetdgjkjxqfspwgduiiiadtdgjmpgjlmyftygiziunygnroenrhadljpgmkxgqmpfdhsdztdxqjrqllvwwd.\n",
            "zxsjibdbjfbjkbdhjxxshusztaddpgcs.\n",
            ".\n",
            "kodziitziidaodch.\n",
            "to.\n",
            "nr.\n",
            "gfnvabjxatlvapfm.\n",
            "zksavdyktsdhadyqwwetdpmodrkwrt.\n",
            "oennhmydukfk.\n",
            "nnwpgfyddzqmraiusstaduvc.\n",
            "zpionz.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI8i-IToZxtd",
        "outputId": "dda585cb-2d77-477c-fe9d-8177378d3c2b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([54, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmYG9lDCaddg",
        "outputId": "60c19018-4847-4836-d160-f1b2e67aa75e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.5674, -0.2373, -0.0274,  ..., -0.0707,  2.4968,  2.4448],\n",
              "        [-0.6701, -1.2199,  0.3031,  ...,  0.8032,  0.5411, -1.1646],\n",
              "        [ 0.1476, -1.0006,  0.3801,  ..., -0.6279,  0.0770, -1.1641],\n",
              "        ...,\n",
              "        [ 0.5283, -0.9056, -0.0124,  ..., -0.9310, -0.0919,  0.1651],\n",
              "        [-0.7125,  0.6541,  0.8071,  ..., -1.1854,  1.0008,  0.9374],\n",
              "        [-0.2512, -0.8699,  0.5397,  ...,  0.0908, -0.4618, -0.8567]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------Our Actual Network------------------\n",
        "\n",
        "# gradient descent\n",
        "for k in range(200): # 200 iterations of the gradient descent\n",
        "\n",
        "  # forward pass\n",
        "  xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "  xenc = xenc.view(-1, 27*2) # flatten to input to the network\n",
        "  logits = xenc @ W # predict log-counts, after matrix multiplication we get a (num, 27)-matrix\n",
        "  counts = logits.exp() # counts\n",
        "  probs = counts / counts.sum(1, keepdims=True) # `probs` is a matrix,\n",
        "                                                # `probs[torch.arange(num), ys]` below\n",
        "                                                # selects for each example the prob assigned by the model to the last character of the trigram\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean() # the fst term computes the average negative log-likelihood loss for the current batch of data\n",
        "                                                                         # the snd term is a L2 regularization, aka weight decay, that penalizes large weights\n",
        "                                                                         # depending of the strenght parameter, here 0.01.\n",
        "  if k % 10 == 0:\n",
        "        print(f\"{k}: {loss.item():.4f}\")\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # update weights\n",
        "  W.data -= 50 * W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4Cybt9m37EQ",
        "outputId": "1713a815-f7bf-40c4-c703-101990043835"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 4.1960\n",
            "10: 2.5104\n",
            "20: 2.3861\n",
            "30: 2.3394\n",
            "40: 2.3152\n",
            "50: 2.3007\n",
            "60: 2.2912\n",
            "70: 2.2844\n",
            "80: 2.2794\n",
            "90: 2.2755\n",
            "100: 2.2724\n",
            "110: 2.2699\n",
            "120: 2.2679\n",
            "130: 2.2662\n",
            "140: 2.2647\n",
            "150: 2.2635\n",
            "160: 2.2624\n",
            "170: 2.2615\n",
            "180: 2.2607\n",
            "190: 2.2599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpafq8CUtz9N",
        "outputId": "de5c1427-b375-4c51-ae92-1926cba312b5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.1582,  2.5806,  0.2739,  ..., -1.0979,  0.9909,  0.8251],\n",
              "        [ 1.2707,  0.4196, -0.2165,  ..., -1.5259, -0.1087, -0.2081],\n",
              "        [ 0.4628,  1.3754, -0.0873,  ..., -0.4159,  0.6824, -1.1060],\n",
              "        ...,\n",
              "        [ 0.5852,  0.4906, -0.4283,  ...,  0.6958,  0.2371,  0.0636],\n",
              "        [ 1.5921,  1.9269, -0.6454,  ..., -0.9071, -1.6581,  0.0755],\n",
              "        [ 0.3606,  2.1695, -0.3000,  ..., -0.3426,  1.5105,  0.3133]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# last, sample from the 'neural net' model\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "  out = []\n",
        "  ix1 = 0\n",
        "  ix2 = 0\n",
        "  while True:\n",
        "\n",
        "    xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=27).float()\n",
        "    xenc = xenc.view(-1, 27*2)\n",
        "    logits = xenc @ W # predict log-counts\n",
        "    counts = logits.exp() # counts\n",
        "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "\n",
        "    ix1 = ix2\n",
        "    ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix2])\n",
        "    if ix2 == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "id": "jX840biSgSjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "795004d2-8d87-4f0d-b530-d3fe82248ae3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aunide.\n",
            "aliasad.\n",
            "ushfay.\n",
            "ainn.\n",
            "aui.\n",
            "ritoleras.\n",
            "get.\n",
            "usannaauranileniassibdainrwi.\n",
            "ol.\n",
            "seisiely.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ex2: split up the dataset randomly into 80% train set, 10% dev set, 10% test set. Train the bigram and trigram models only on the training set. Evaluate them on dev and test splits. What can you see?"
      ],
      "metadata": {
        "id": "SCxjbE3oWUOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "block_size = 2 # context length: how many characters do we take to predict the next one\n",
        "\n",
        "def build_dataset(words):\n",
        "  X, Y = [], [] # `X` will store the input data and `Y` the labels\n",
        "  for w in words:\n",
        "\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  return X, Y"
      ],
      "metadata": {
        "id": "-rVHEvyBXQv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = build_dataset(words)\n",
        "X.shape, Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd8MkrikmU51",
        "outputId": "4deabf27-55de-484a-fd21-8586745b81dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([228146, 2]), torch.Size([228146]))"
            ]
          },
          "metadata": {},
          "execution_count": 594
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[:5], Y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-0bjb1WqSWB",
        "outputId": "bfc42c46-dd6a-4de0-8c30-b8ab83e625dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  0],\n",
              "         [ 0,  5],\n",
              "         [ 5, 13],\n",
              "         [13, 13],\n",
              "         [13,  1]]),\n",
              " tensor([ 5, 13, 13,  1,  0]))"
            ]
          },
          "metadata": {},
          "execution_count": 595
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words)) # we require `int()` to convert the float `0.8*len(words)` back into a natural number that can be used below as an index\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr, Ytr = build_dataset(words[:n1])\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])\n",
        "Xte, Yte = build_dataset(words[n2:])"
      ],
      "metadata": {
        "id": "VVjdL3tRuI7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtr.shape, Ytr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWt2CuJNyCor",
        "outputId": "29aa7bb7-5317-4bad-cced-5b8b6ec00edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([182625, 2]), torch.Size([182625]))"
            ]
          },
          "metadata": {},
          "execution_count": 597
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xdev.shape, Ydev.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLv2iGJXyL5V",
        "outputId": "9562d458-5665-441b-b69a-ff475e718b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([22655, 2]), torch.Size([22655]))"
            ]
          },
          "metadata": {},
          "execution_count": 598
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xte.shape, Yte.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBuBb2_MyfKK",
        "outputId": "a3a60838-ac07-45f5-dc9a-124106fc0121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([22866, 2]), torch.Size([22866]))"
            ]
          },
          "metadata": {},
          "execution_count": 599
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinitialize the 'network'\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27+27, 27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "id": "PISg7jUJygEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model on the training set\n",
        "\n",
        "# gradient descent\n",
        "for k in range(200): # 200 iterations of the gradient descent\n",
        "\n",
        "  # forward pass\n",
        "  xenc = F.one_hot(Xtr, num_classes=27).float() # input to the network: one-hot encoding\n",
        "  xenc = xenc.view(-1, 27*2) # flatten to input to the network\n",
        "  logits = xenc @ W # predict log-counts, after matrix multiplication we get a (num, 27)-matrix\n",
        "  counts = logits.exp() # counts\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  numtr = len(Xtr)\n",
        "  loss = -probs[torch.arange(numtr), Ytr].log().mean() + 0.01*(W**2).mean()\n",
        "  if k % 10 == 0:\n",
        "        print(f\"{k}: {loss.item():.4f}\")\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # update weights\n",
        "  W.data -= 50 * W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPbA-BPBzgqY",
        "outputId": "1ce48b55-152e-40b9-ac32-544990a1e217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 2.3581\n",
            "10: 2.3572\n",
            "20: 2.3566\n",
            "30: 2.3787\n",
            "40: 2.3885\n",
            "50: 2.3769\n",
            "60: 2.3875\n",
            "70: 2.3766\n",
            "80: 2.3868\n",
            "90: 2.3763\n",
            "100: 2.3864\n",
            "110: 2.3760\n",
            "120: 2.3860\n",
            "130: 2.3757\n",
            "140: 2.3857\n",
            "150: 2.3755\n",
            "160: 2.3855\n",
            "170: 2.3753\n",
            "180: 2.3853\n",
            "190: 2.3752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(X, Y, W):\n",
        "    xenc = F.one_hot(X, num_classes = 27).float()\n",
        "    xenc = xenc.view(-1, 27*2)\n",
        "\n",
        "    # probs is softmax\n",
        "    logits = xenc @ W\n",
        "    counts = torch.exp(logits)\n",
        "    probs = counts / counts.sum(dim = 1, keepdim = True)\n",
        "\n",
        "    # loss (normalized negative log likelihood)\n",
        "    loss = - probs[torch.arange(len(X)), Y].log().mean() + 0.01*(W**2).mean()\n",
        "\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "Ou8Y1Ysm22PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Train Loss: {loss(Xtr, Ytr, W):.4f}\")\n",
        "print(f\"Dev Loss: {loss(Xdev, Ydev, W):.4f}\")\n",
        "print(f\"Test Loss: {loss(Xte, Yte, W):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1gLR13b50_e",
        "outputId": "0d488c3d-6f17-439d-c330-b061159c4484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.3851\n",
            "Dev Loss: 2.3837\n",
            "Test Loss: 2.3897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No significant variance between train/dev/test sets, so no sign of overfitting or underfitting. Can we fine-tune the parameters during the dev phase to slightly improve performance?"
      ],
      "metadata": {
        "id": "_xd6Kode9Kyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "  out = []\n",
        "  ix1 = 0\n",
        "  ix2 = 0\n",
        "  while True:\n",
        "\n",
        "    xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=27).float()\n",
        "    xenc = xenc.view(-1, 27*2)\n",
        "    logits = xenc @ W # predict log-counts\n",
        "    counts = logits.exp() # counts\n",
        "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "\n",
        "    ix1 = ix2\n",
        "    ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix2])\n",
        "    if ix2 == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eenYD9k6Jf3",
        "outputId": "74fb0862-5f26-4d2d-e9b5-4633c8a22340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "juwide.\n",
            "janasad.\n",
            "alen.\n",
            "amainn.\n",
            "kai.\n",
            "ritoleras.\n",
            "tee.\n",
            "adannaauranileniassibdainrwi.\n",
            "ta.\n",
            "saisiely.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ex3: use the dev set to tune the strength of smoothing (or regularization) for the trigram model - i.e. try many possibilities and see which one works best based on the dev set loss. What patterns can you see in the train and dev set loss as you tune this strength? Take the best setting of the smoothing and evaluate on the test set once and at the end. How good of a loss do you achieve?"
      ],
      "metadata": {
        "id": "iu0JgKzX-RC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fine-tune the parameters\n",
        "\n",
        "# gradient descent\n",
        "for k in range(20):\n",
        "\n",
        "  # forward pass\n",
        "  xenc = F.one_hot(Xdev, num_classes=27).float()\n",
        "  xenc = xenc.view(-1, 27*2)\n",
        "  logits = xenc @ W\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  numdev = len(Xdev)\n",
        "  loss = -probs[torch.arange(numdev), Ydev].log().mean() + 0.01*(W**2).mean()\n",
        "  print(f\"{k}: {loss.item():.4f}\")\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # update weights\n",
        "  W.data -= 50 * W.grad\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZJMX39S_xNK",
        "outputId": "e64ac292-3b0f-4122-ccc9-00df6167e78e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 2.3447\n",
            "1: 2.3437\n",
            "2: 2.3430\n",
            "3: 2.3423\n",
            "4: 2.3417\n",
            "5: 2.3411\n",
            "6: 2.3406\n",
            "7: 2.3402\n",
            "8: 2.3398\n",
            "9: 2.3394\n",
            "10: 2.3391\n",
            "11: 2.3387\n",
            "12: 2.3384\n",
            "13: 2.3382\n",
            "14: 2.3379\n",
            "15: 2.3377\n",
            "16: 2.3375\n",
            "17: 2.3375\n",
            "18: 2.3379\n",
            "19: 2.3395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I tried various regularization strengths, 0.01 seems to give the best results."
      ],
      "metadata": {
        "id": "eCT_DQnTFalA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We take the best setting of the smoothing and evaluate on the test set once more\n",
        "\n",
        "xenc = F.one_hot(Xte, num_classes=27).float()\n",
        "xenc = xenc.view(-1, 27*2)\n",
        "logits = xenc @ W\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(1, keepdims=True)\n",
        "numte = len(Xte)\n",
        "loss = -probs[torch.arange(numte), Yte].log().mean() + 0.001*(W**2).mean()\n",
        "print(f\"Test Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHqSB0deGGZl",
        "outputId": "343f8074-1d0c-4d04-bfa2-c6755f405675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.3605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We decreased a bit our loss wrt the one on the dev set.    "
      ],
      "metadata": {
        "id": "3ubrtY15KvnN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ex4: we saw that our 1-hot vectors merely select a row of W, so producing these vectors explicitly feels wasteful. Can you delete our use of F.one_hot in favor of simply indexing into rows of W?"
      ],
      "metadata": {
        "id": "WKvM2Hfa2w4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# case of bigrams\n",
        "\n",
        "# create the training set of bigrams (x,y)\n",
        "xs, ys = [], []\n",
        "\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ],
      "metadata": {
        "id": "4QWhdyzvLpKc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PQQMouCrceB",
        "outputId": "eb68fb33-aa6f-4764-898f-e7cac716fa39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([228146])"
            ]
          },
          "metadata": {},
          "execution_count": 683
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# randomly initialize 27 neurons' weights. each neuron receives 27 inputs\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "id": "jVWjkmxPqyUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W[xs].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmlt__KIsU1d",
        "outputId": "152c093e-5e1f-49d6-adc8-9a20e2550aa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([228146, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 685
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient descent\n",
        "for k in range(10):\n",
        "\n",
        "  # forward pass\n",
        "  logits = W[xs] # we directly index into W instead of using one_hot encoding\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  loss = -probs[torch.arange(len(xs)), ys].log().mean() + 0.01*(W**2).mean()\n",
        "  print(loss.item())\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  W.data += -50 * W.grad\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVS86BHhq-s0",
        "outputId": "c35a9f5d-4392-4419-c25f-4984e40bca75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.7686190605163574\n",
            "3.3787858486175537\n",
            "3.1610772609710693\n",
            "3.027181625366211\n",
            "2.9344804286956787\n",
            "2.8672285079956055\n",
            "2.81665301322937\n",
            "2.777146100997925\n",
            "2.745253562927246\n",
            "2.7188308238983154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we come back to the case of bigrams\n",
        "\n",
        "# create the training dataset\n",
        "xs, ys = [], []\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    iy = stoi[ch3]\n",
        "    xs.append([ix1, ix2])\n",
        "    ys.append(iy)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ],
      "metadata": {
        "id": "R3gKvpIDrRWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinitialize the 'network'\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27+27, 27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "id": "Q_Q0Us3kvpLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AX3EqYD8wv8C",
        "outputId": "61ed8ae2-3d24-4f28-bb0a-19f72bceee1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([196113, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 689
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xs[:,0].shape # is the tensor (1d-tensor, i.e. vector) of all the first elements of our 196,113 pairs of indices in our training dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7gBg6ObyKAH",
        "outputId": "ed457760-8c7f-4559-fc92-ee438b115560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([196113])"
            ]
          },
          "metadata": {},
          "execution_count": 690
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W[xs[:,0]].shape # is thus the lines of W corresponding to each of the indices in xs[:,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpHBeeu405JZ",
        "outputId": "9a4d9b48-300e-49f6-cab5-acf45c79e396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([196113, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 691
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient descent\n",
        "for k in range(200):\n",
        "\n",
        "  # forward pass\n",
        "  logits = W[xs[:,0]] + W[27 + xs[:,1]] # we directly index into W insteaf of using one_hot encoding\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  loss = -probs[torch.arange(len(xs)), ys].log().mean() + 0.01*(W**2).mean()\n",
        "  if k % 10 == 0:\n",
        "        print(f\"{k}: {loss.item():.4f}\")\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # update weights\n",
        "  W.data -= 50 * W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML9dIG7tu7M2",
        "outputId": "2ad22c39-f5c0-4f4c-c453-81a569d8cfea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 4.1960\n",
            "10: 2.5104\n",
            "20: 2.3861\n",
            "30: 2.3394\n",
            "40: 2.3152\n",
            "50: 2.3007\n",
            "60: 2.2912\n",
            "70: 2.2844\n",
            "80: 2.2794\n",
            "90: 2.2755\n",
            "100: 2.2724\n",
            "110: 2.2699\n",
            "120: 2.2679\n",
            "130: 2.2662\n",
            "140: 2.2647\n",
            "150: 2.2635\n",
            "160: 2.2624\n",
            "170: 2.2615\n",
            "180: 2.2607\n",
            "190: 2.2599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ex5: look up and use F.cross_entropy instead. You should achieve the same result. Can you think of why we'd prefer to use F.cross_entropy instead?"
      ],
      "metadata": {
        "id": "qFMV16FI3Gq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinitialize the 'network'\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27+27, 27), generator=g, requires_grad=True)"
      ],
      "metadata": {
        "id": "3Y5_QkX52cr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient descent\n",
        "for k in range(200):\n",
        "\n",
        "  # forward pass\n",
        "  logits = W[xs[:,0]] + W[27 + xs[:,1]] #predict log-counts, directly indexing into W\n",
        "  loss = F.cross_entropy(logits, ys) + 0.01*(W**2).mean() # choose cross entropy as the loss function instead of NLL\n",
        "  if k % 10 == 0:\n",
        "        print(f\"{k}: {loss.item():.4f}\")\n",
        "\n",
        "  # backward pass\n",
        "  W.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # update weights\n",
        "  W.data -= 50 * W.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPiIx1LDMLhR",
        "outputId": "8a505be1-9f67-4ad4-f22e-255062010d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 4.1960\n",
            "10: 2.5104\n",
            "20: 2.3861\n",
            "30: 2.3394\n",
            "40: 2.3152\n",
            "50: 2.3007\n",
            "60: 2.2912\n",
            "70: 2.2844\n",
            "80: 2.2794\n",
            "90: 2.2755\n",
            "100: 2.2724\n",
            "110: 2.2699\n",
            "120: 2.2679\n",
            "130: 2.2662\n",
            "140: 2.2647\n",
            "150: 2.2635\n",
            "160: 2.2624\n",
            "170: 2.2615\n",
            "180: 2.2607\n",
            "190: 2.2599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keeping the same learning rate, weigth decay and training dataset `xs`, we achieve the same result with cross entropy. However, the code is slightly simplified, since `F.cross_entropy` automatically applies a softmax to convert logits into probabilities. Also, combining softmax and log probabilities into a single step reduces the risk of numerical instability.  "
      ],
      "metadata": {
        "id": "mCIcjIXHPJTb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "paBKP2zHVqB9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}